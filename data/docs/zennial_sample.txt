Zennial AI System Documentation

System Architecture:
The system uses a FastAPI backend (optional), LangGraph workflows for orchestration, and a memory layer
built on ChromaDB for long-term storage. Documents are chunked and embedded with sentence-transformers,
then stored in a RAG collection.

Installation:
1. Create conda env with Python 3.11
2. Install dependencies from requirements.txt
3. Run ingestion to index docs

Usage:
Ask questions like "What does the system architecture say?" and the RAG pipeline will return relevant snippets
and an answer generated by Gemini.